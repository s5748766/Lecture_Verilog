#!/usr/bin/env python3
"""
êµí†µìˆ˜ë‹¨ ë¶„ë¥˜ê¸° (Airplanes, Cars, Ships) - ì–‘ìí™” ëª¨ë¸ ì „ìš©
UINT8 ì–‘ìí™” ëª¨ë¸ ì§€ì› (INT8 Quantization)
"""

import sys
import os
import time
import argparse
import numpy as np
from PIL import Image
import json
from datetime import datetime
import platform

# TensorFlow Lite ì„í¬íŠ¸
try:
    import tflite_runtime.interpreter as tflite
    TF_LITE_RUNTIME = True
    print("âœ“ TFLite Runtime ì‚¬ìš©")
except ImportError:
    try:
        import tensorflow.lite as tflite
        TF_LITE_RUNTIME = False
        print("âœ“ TensorFlow Lite ì‚¬ìš©")
    except ImportError:
        print("\n" + "="*70)
        print("âŒ ì˜¤ë¥˜: TensorFlow Liteë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("="*70)
        print("\nì„¤ì¹˜ ë°©ë²•:")
        print("  pip install tflite-runtime")
        print("  ë˜ëŠ”")
        print("  pip install tensorflow")
        print("\n" + "="*70)
        sys.exit(1)


class VehicleClassifierQuantized:
    """êµí†µìˆ˜ë‹¨ ë¶„ë¥˜ ëª¨ë¸ ë˜í¼ (ì–‘ìí™” ëª¨ë¸ ì „ìš©)"""
    
    def __init__(self, model_path, labels_path, verbose=True):
        """
        ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_path: .tflite ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            labels_path: labels.txt íŒŒì¼ ê²½ë¡œ
            verbose: ìƒì„¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
        """
        self.model_path = model_path
        self.labels_path = labels_path
        self.verbose = verbose
        
        # í”Œë«í¼ ì •ë³´
        self.platform = platform.system()
        
        # ëª¨ë¸ ì¡´ì¬ í™•ì¸
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        if not os.path.exists(labels_path):
            raise FileNotFoundError(f"ë¼ë²¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labels_path}")
        
        # ë¼ë²¨ ë¡œë“œ
        self.labels = self._load_labels()
        
        # TFLite ì¸í„°í”„ë¦¬í„° ìƒì„±
        try:
            self.interpreter = tflite.Interpreter(model_path=model_path)
            self.interpreter.allocate_tensors()
        except Exception as e:
            raise RuntimeError(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ì…ì¶œë ¥ í…ì„œ ì •ë³´
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        
        # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
        self.input_shape = self.input_details[0]['shape']
        self.height = self.input_shape[1]
        self.width = self.input_shape[2]
        self.channels = self.input_shape[3]
        
        # ì…ì¶œë ¥ ë°ì´í„° íƒ€ì…
        self.input_dtype = self.input_details[0]['dtype']
        self.output_dtype = self.output_details[0]['dtype']
        
        # ì–‘ìí™” íŒŒë¼ë¯¸í„°
        self.input_scale, self.input_zero_point = self.input_details[0]['quantization']
        self.output_scale, self.output_zero_point = self.output_details[0]['quantization']
        
        # ì–‘ìí™” ëª¨ë¸ í™•ì¸
        self.is_quantized = (self.input_dtype == np.uint8 or self.input_dtype == np.int8)
        
        if not self.is_quantized:
            print("\nâš ï¸  ê²½ê³ : ì´ ëª¨ë¸ì€ ì–‘ìí™” ëª¨ë¸ì´ ì•„ë‹™ë‹ˆë‹¤!")
            print("    Float ëª¨ë¸ì€ vehicle_classifier.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        if self.verbose:
            self._print_model_info()
    
    def _print_model_info(self):
        """ëª¨ë¸ ì •ë³´ ì¶œë ¥"""
        print("\n" + "="*70)
        print(f"ğŸ–¥ï¸  í”Œë«í¼: {self.platform}")
        print(f"ğŸ Python: {sys.version.split()[0]}")
        print("="*70)
        print("ğŸš— êµí†µìˆ˜ë‹¨ ë¶„ë¥˜ ëª¨ë¸ ì •ë³´ (ì–‘ìí™” ëª¨ë¸)")
        print("="*70)
        print(f"ëª¨ë¸ íŒŒì¼: {os.path.basename(self.model_path)}")
        print(f"ëª¨ë¸ ê²½ë¡œ: {self.model_path}")
        print(f"ë¼ë²¨ íŒŒì¼: {os.path.basename(self.labels_path)}")
        print(f"ì…ë ¥ í¬ê¸°: {self.width}x{self.height}x{self.channels}")
        print(f"ì…ë ¥ íƒ€ì…: {self.input_dtype.__name__}")
        print(f"ì¶œë ¥ íƒ€ì…: {self.output_dtype.__name__}")
        print(f"í´ë˜ìŠ¤ ìˆ˜: {len(self.labels)}")
        print(f"í´ë˜ìŠ¤ ëª©ë¡:")
        for i, label in enumerate(self.labels):
            print(f"  [{i}] {label}")
        
        # ì–‘ìí™” ì •ë³´
        if self.is_quantized:
            print(f"\nâœ“ ì–‘ìí™” ëª¨ë¸ (UINT8/INT8)")
            print(f"  ì…ë ¥ ì–‘ìí™”: scale={self.input_scale:.8f}, zero_point={self.input_zero_point}")
            print(f"  ì¶œë ¥ ì–‘ìí™”: scale={self.output_scale:.8f}, zero_point={self.output_zero_point}")
        else:
            print(f"\nâœ“ Float ëª¨ë¸ (FP32)")
        
        print(f"\nâš™ï¸  ì „ì²˜ë¦¬: ì–‘ìí™” ëª¨ë¸ìš© (UINT8 [0, 255])")
        print(f"âš™ï¸  ìµœì í™”: {self.platform} ({'ë©€í‹° ìŠ¤ë ˆë“œ' if self.platform == 'Windows' else 'ARM ìµœì í™”'})")
        print("="*70 + "\n")
    
    def _load_labels(self):
        """ë¼ë²¨ íŒŒì¼ ë¡œë“œ"""
        labels = []
        try:
            with open(self.labels_path, 'r', encoding='utf-8') as f:
                for line in f:
                    label = line.strip()
                    # ë¹ˆ ì¤„ì´ë‚˜ 'EOF' ê°™ì€ ë¶ˆí•„ìš”í•œ ë¼ë²¨ ì œì™¸
                    if label and label.upper() not in ['EOF', '']:
                        labels.append(label)
        except Exception as e:
            raise RuntimeError(f"ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if len(labels) == 0:
            raise ValueError("ë¼ë²¨ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        return labels
    
    def preprocess_image(self, image_path_or_image):
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì–‘ìí™” ëª¨ë¸ìš©)
        
        Args:
            image_path_or_image: ì´ë¯¸ì§€ ê²½ë¡œ(str) ë˜ëŠ” PIL Image ê°ì²´
            
        Returns:
            ì „ì²˜ë¦¬ëœ numpy ë°°ì—´ (UINT8)
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            if isinstance(image_path_or_image, str):
                if not os.path.exists(image_path_or_image):
                    raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path_or_image}")
                img = Image.open(image_path_or_image)
            else:
                img = image_path_or_image
            
            # RGB ë³€í™˜
            img = img.convert('RGB')
            
            # í¬ê¸° ì¡°ì • (ê³ í’ˆì§ˆ ë¦¬ìƒ˜í”Œë§)
            img = img.resize((self.width, self.height), Image.LANCZOS)
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜ - UINT8 ìœ ì§€
            img_array = np.array(img, dtype=np.uint8)
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [1, height, width, channels]
            img_array = np.expand_dims(img_array, axis=0)
            
            return img_array
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
            return None
    
    def predict(self, image_path):
        """
        ì´ë¯¸ì§€ ë¶„ë¥˜ ì˜ˆì¸¡
        
        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            
        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼
        """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        input_data = self.preprocess_image(image_path)
        if input_data is None:
            return None
        
        # ì¶”ë¡  ì‹œì‘
        start_time = time.time()
        
        try:
            self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
            self.interpreter.invoke()
            
            # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            output_data = self.interpreter.get_tensor(self.output_details[0]['index'])
            output_data = output_data[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
        
        inference_time = (time.time() - start_time) * 1000  # ms
        
        # ì—­ì–‘ìí™” ë° í™•ë¥  ê³„ì‚°
        if self.is_quantized and self.output_dtype == np.uint8:
            # UINT8 ì¶œë ¥ì„ Floatë¡œ ë³€í™˜ (ì—­ì–‘ìí™”)
            output_float = (output_data.astype(np.float32) - self.output_zero_point) * self.output_scale
            
            # Softmax ì ìš©
            exp_values = np.exp(output_float - np.max(output_float))
            probabilities = exp_values / exp_values.sum()
        else:
            # Float ì¶œë ¥ (ì¼ë°˜ì ìœ¼ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŒ)
            output_float = output_data.astype(np.float32)
            
            # Softmax í•„ìš” ì—¬ë¶€ í™•ì¸
            if 0.99 < output_float.sum() < 1.01:
                probabilities = output_float
            else:
                exp_values = np.exp(output_float - np.max(output_float))
                probabilities = exp_values / exp_values.sum()
        
        # ìµœê³  í™•ë¥  í´ë˜ìŠ¤
        predicted_index = np.argmax(probabilities)
        confidence = float(probabilities[predicted_index])
        predicted_label = self.labels[predicted_index] if predicted_index < len(self.labels) else "Unknown"
        
        return {
            'label': predicted_label,
            'confidence': confidence,
            'probabilities': probabilities.tolist(),
            'inference_time': inference_time,
            'predicted_index': int(predicted_index),
            'raw_output': output_data.tolist() if self.verbose else None
        }


def print_single_result(result, labels, platform, show_all=True):
    """ë‹¨ì¼ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥"""
    if result is None:
        print("âŒ ì˜ˆì¸¡ ì‹¤íŒ¨")
        return
    
    # ì´ëª¨ì§€ ì„ íƒ
    emoji_map = {
        'airplanes': 'âœˆï¸',
        'cars': 'ğŸš—',
        'ships': 'ğŸš¢'
    }
    emoji = emoji_map.get(result['label'], 'ğŸ“¦')
    
    print("\n" + "="*70)
    print(f"ğŸš— ì˜ˆì¸¡ ê²°ê³¼ [{platform}]")
    print("="*70)
    print(f"âœ“ ì˜ˆì¸¡ í´ë˜ìŠ¤: {result['label'].upper()}")
    print(f"âœ“ ì‹ ë¢°ë„: {result['confidence']*100:.2f}%")
    print(f"âœ“ ì¶”ë¡  ì‹œê°„: {result['inference_time']:.2f}ms")
    
    if show_all:
        print("\nğŸ“Š ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥ :")
        print("-"*70)
        
        probs = np.array(result['probabilities'])
        
        # ë¼ë²¨ ê°œìˆ˜ë§Œí¼ë§Œ ì¶œë ¥
        for idx in range(len(labels)):
            label_name = labels[idx]
            prob = probs[idx] if idx < len(probs) else 0.0
            bar_length = int(prob * 50)
            bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
            emoji = emoji_map.get(label_name, 'ğŸ“¦')
            print(f"  {emoji} {label_name:12s} | {prob*100:6.2f}% | {bar}")
    
    print("="*70)


def test_single_image(classifier, image_path, show_all=True):
    """ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ“¸ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸: {image_path}")
    print("="*70)
    
    result = classifier.predict(image_path)
    print_single_result(result, classifier.labels, classifier.platform, show_all)
    
    return result


def test_directory(classifier, directory, save_results=None):
    """ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"""
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp']
    image_files = []
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            if any(file.lower().endswith(ext) for ext in image_extensions):
                image_files.append(os.path.join(root, file))
    
    if not image_files:
        print(f"âŒ ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {directory}")
        return []
    
    print(f"\nğŸ“‚ ë””ë ‰í† ë¦¬: {directory}")
    print(f"ğŸ“Š ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
    print("="*70)
    
    results = []
    total_time = 0
    
    for i, img_path in enumerate(image_files, 1):
        filename = os.path.basename(img_path)
        print(f"\n[{i}/{len(image_files)}] {filename}")
        
        result = classifier.predict(img_path)
        
        if result:
            total_time += result['inference_time']
            results.append({
                'file': filename,
                'path': img_path,
                'label': result['label'],
                'confidence': result['confidence'],
                'inference_time': result['inference_time'],
                'probabilities': result['probabilities']
            })
            
            # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
            emoji_map = {'airplanes': 'âœˆï¸', 'cars': 'ğŸš—', 'ships': 'ğŸš¢'}
            emoji = emoji_map.get(result['label'], 'ğŸ“¦')
            print(f"  {emoji} {result['label']:12s} | {result['confidence']*100:6.2f}% | {result['inference_time']:6.2f}ms")
        else:
            print(f"  âŒ ì˜ˆì¸¡ ì‹¤íŒ¨")
    
    # ìš”ì•½
    print_summary(results, len(image_files), total_time)
    
    # ê²°ê³¼ ì €ì¥
    if save_results and results:
        save_results_to_json(results, save_results)
    
    return results


def test_subdirectories(classifier, root_dir, save_results=None):
    """í•˜ìœ„ ë””ë ‰í† ë¦¬ë³„ë¡œ í…ŒìŠ¤íŠ¸"""
    
    print(f"\nğŸ“‚ ë£¨íŠ¸ ë””ë ‰í† ë¦¬: {root_dir}")
    print("="*70)
    
    all_results = {}
    
    # ê° í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ í…ŒìŠ¤íŠ¸
    for label in classifier.labels:
        subdir = os.path.join(root_dir, label)
        
        if not os.path.isdir(subdir):
            print(f"\nâš ï¸  ë””ë ‰í† ë¦¬ ì—†ìŒ: {subdir}")
            continue
        
        print(f"\n{'='*70}")
        print(f"ğŸ“ {label.upper()} í…ŒìŠ¤íŠ¸")
        print(f"{'='*70}")
        
        results = test_directory(classifier, subdir, save_results=None)
        
        if results:
            all_results[label] = results
            
            # ì •í™•ë„ ê³„ì‚°
            correct = sum(1 for r in results if r['label'] == label)
            accuracy = (correct / len(results)) * 100
            
            print(f"\nâœ“ {label} ì •í™•ë„: {correct}/{len(results)} ({accuracy:.1f}%)")
    
    # ì „ì²´ ìš”ì•½
    print_overall_summary(all_results, classifier.labels)
    
    # ê²°ê³¼ ì €ì¥
    if save_results:
        save_all_results_to_json(all_results, save_results, classifier.platform)
    
    return all_results


def print_summary(results, total_images, total_time):
    """í…ŒìŠ¤íŠ¸ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*70)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½")
    print("="*70)
    print(f"ì´ ì´ë¯¸ì§€: {total_images}")
    print(f"ì„±ê³µ: {len(results)}")
    print(f"ì‹¤íŒ¨: {total_images - len(results)}")
    
    if results:
        print(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {total_time/len(results):.2f}ms")
        
        print("\ní´ë˜ìŠ¤ë³„ ë¶„í¬:")
        print("-"*70)
        
        class_counts = {}
        for r in results:
            label = r['label']
            class_counts[label] = class_counts.get(label, 0) + 1
        
        emoji_map = {'airplanes': 'âœˆï¸', 'cars': 'ğŸš—', 'ships': 'ğŸš¢'}
        for label, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(results)) * 100
            emoji = emoji_map.get(label, 'ğŸ“¦')
            bar_length = int(percentage / 2)
            bar = "â–ˆ" * bar_length
            print(f"  {emoji} {label:12s}: {count:3d} ({percentage:5.1f}%) {bar}")
    
    print("="*70)


def print_overall_summary(all_results, labels):
    """ì „ì²´ ìš”ì•½"""
    print("\n" + "="*70)
    print("ğŸ¯ ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½")
    print("="*70)
    
    total_images = 0
    total_correct = 0
    
    emoji_map = {'airplanes': 'âœˆï¸', 'cars': 'ğŸš—', 'ships': 'ğŸš¢'}
    
    print("\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:")
    print("-"*70)
    
    for label in labels:
        if label not in all_results:
            continue
        
        results = all_results[label]
        correct = sum(1 for r in results if r['label'] == label)
        total = len(results)
        accuracy = (correct / total) * 100 if total > 0 else 0
        
        total_images += total
        total_correct += correct
        
        emoji = emoji_map.get(label, 'ğŸ“¦')
        bar_length = int(accuracy / 2)
        bar = "â–ˆ" * bar_length
        print(f"  {emoji} {label:12s}: {correct:3d}/{total:3d} ({accuracy:6.2f}%) {bar}")
    
    overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0
    
    print("-"*70)
    print(f"  ğŸ¯ ì „ì²´ ì •í™•ë„: {total_correct}/{total_images} ({overall_accuracy:.2f}%)")
    print("="*70)


def save_results_to_json(results, output_path):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        output_data = {
            'timestamp': datetime.now().isoformat(),
            'total_images': len(results),
            'results': results
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ ê²°ê³¼ ì €ì¥: {output_path}")
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def save_all_results_to_json(all_results, output_path, platform):
    """ëª¨ë“  í´ë˜ìŠ¤ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        stats = {}
        total_images = 0
        total_correct = 0
        
        for label, results in all_results.items():
            correct = sum(1 for r in results if r['label'] == label)
            total = len(results)
            accuracy = (correct / total) * 100 if total > 0 else 0
            
            total_images += total
            total_correct += correct
            
            stats[label] = {
                'total': total,
                'correct': correct,
                'accuracy': accuracy
            }
        
        overall_accuracy = (total_correct / total_images) * 100 if total_images > 0 else 0
        
        output_data = {
            'timestamp': datetime.now().isoformat(),
            'platform': platform,
            'model_type': 'quantized_uint8',
            'overall_accuracy': overall_accuracy,
            'total_images': total_images,
            'total_correct': total_correct,
            'class_stats': stats,
            'detailed_results': all_results
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ ì „ì²´ ê²°ê³¼ ì €ì¥: {output_path}")
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='êµí†µìˆ˜ë‹¨ ë¶„ë¥˜ê¸° (ì–‘ìí™” ëª¨ë¸ ì „ìš©)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  ë‹¨ì¼ ì´ë¯¸ì§€:
    python %(prog)s -m model.tflite -l labels.txt -i test.jpg
  
  ë””ë ‰í† ë¦¬:
    python %(prog)s -m model.tflite -l labels.txt -d test_images/
  
  í´ë˜ìŠ¤ë³„ í‰ê°€:
    python %(prog)s -m model.tflite -l labels.txt -s test_images/ -o results.json
        """
    )
    
    parser.add_argument('-m', '--model', required=True,
                       help='TFLite ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ì–‘ìí™” ëª¨ë¸)')
    parser.add_argument('-l', '--labels', required=True,
                       help='ë¼ë²¨ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('-i', '--image',
                       help='í…ŒìŠ¤íŠ¸í•  ë‹¨ì¼ ì´ë¯¸ì§€')
    parser.add_argument('-d', '--directory',
                       help='í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    parser.add_argument('-s', '--subdirs',
                       help='í´ë˜ìŠ¤ë³„ í•˜ìœ„ ë””ë ‰í† ë¦¬ í…ŒìŠ¤íŠ¸')
    parser.add_argument('-o', '--output',
                       help='ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON)')
    parser.add_argument('--no-details', action='store_true',
                       help='ìƒì„¸ ì •ë³´ ìˆ¨ê¸°ê¸°')
    
    args = parser.parse_args()
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        classifier = VehicleClassifierQuantized(args.model, args.labels, verbose=True)
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        if args.image:
            test_single_image(classifier, args.image, show_all=not args.no_details)
        elif args.subdirs:
            test_subdirectories(classifier, args.subdirs, args.output)
        elif args.directory:
            test_directory(classifier, args.directory, args.output)
        else:
            print("âŒ ì˜¤ë¥˜: -i, -d, ë˜ëŠ” -s ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
            parser.print_help()
            sys.exit(1)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
